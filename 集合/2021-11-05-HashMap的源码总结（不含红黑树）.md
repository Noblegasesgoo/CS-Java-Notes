# HashMap的源码总结（不含红黑树）

## 1、属性总结

### 1.1 总览

|                         属性名                          |                             描述                             |
| :-----------------------------------------------------: | :----------------------------------------------------------: |
|    **static final int MAXIMUM_CAPACITY = 1 << 30;**     | 哈希表的最大大小，绝对也是二的幂，这里 一左移三十位，就是 2^30。 |
| **static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;** | 哈希表的默认大小，绝对是二的幂，这里 一左移四位，就是 2^4 = 16。 |
|   **static final float DEFAULT_LOAD_FACTOR = 0.75f;**   | 默认的加载因子 0.75，乘以数组容量得到的值，用来表示元素个数达到多少时，需要扩容。 |
|       **static final int TREEIFY_THRESHOLD = 8;**       |       当桶(bucket)上的结点数大于这个值时会转成红黑树。       |
|      **static final int UNTREEIFY_THRESHOLD = 6;**      |         当桶(bucket)上的结点数小于这个值时树转链表。         |
|     **static final int MIN_TREEIFY_CAPACITY = 64;**     |         桶中结构转化为红黑树对应的table的最小大小。          |
|            **transient Node<k,v>[] table;**             |               存储元素的数组，总是2的幂次倍。                |
|       **transient Set<map.entry<k,v>> entrySet;**       |                      存放具体元素的集。                      |
|                 **transient int size;**                 |           存放KV的数量（为链表和树中的KV的总和）。           |
|                   **int threshold;**                    |  临界值 当实际大小(容量*填充因子)超过临界值时，会进行扩容。  |
|               **final float loadFactor;**               |                          加载因子。                          |



### 1.2 **loadFactor** 加载因子

- **太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散。**
- **loadFactor** 的默认值为 0.75f 是官方给出的一个比较好的临界值，非必要情况下不建议改动。

### 1.3 **threshold** 扩容临界值

- 当 **size** 大于等于这个值的时候就得考虑哈希表扩容了。



## 2、get方法

### 2.1 方法源码

```java

    public V get(Object key) {
        java.util.HashMap.Node<K,V> e;
        // 返回这个key对应的value。
        return (e = getNode(hash(key), key)) == null ? null : e.value;
    }

    /**
     * Implements Map.get and related methods.
     *
     * @param hash hash for key 传入的key的哈希值。
     * @param key the key 传入的key
     * @return the node, or null if none
     */
    final java.util.HashMap.Node<K,V> getNode(int hash, Object key) {
        // 用来存放当前哈希表。
        java.util.HashMap.Node<K,V>[] tab;
        // 用来存放哈希表中某个桶中的链表的头节点，以及目标节点。
        java.util.HashMap.Node<K,V> first, e;
        // 当前哈希表的容量。
        int n;
        K k;
       /*
            说明一下这个if条件中的条件的意思。
                如果当前哈希表不为空 并且 当前哈希表的容量不为0（顺便赋值给 n 存储）。
            并且
                把 key 的 hash值对数组长度做与运算即可找到当前带查找节点在哈希表中对应的桶，
                并将这个桶的第一个节点用first保存下来，这个头节点还不为空的话，就说明有这个key对应的节点。
        */
        if ((tab = table) != null && (n = tab.length) > 0 &&
                (first = tab[(n - 1) & hash]) != null) {

            // 我们进入到这里就代表了哈希表中是存在这么一个 key 对应的节点的。
            // 如果桶中只有一个节点。
            if (first.hash == hash && // always check first node 总是检查第一个节点。
                    ((k = first.key) == key || (key != null && key.equals(k))))
                // 那这个first节点就是我们要找的key对应的节点。
                return first;

            // 如果桶中不止一个节点。
            if ((e = first.next) != null) {
                // 如果头节点是红黑树节点的话，那么这个桶中装的就是红黑树。
                if (first instanceof java.util.HashMap.TreeNode)
                    // 调用红黑树中查询对应节点的方法，返回我们目标的节点。
                    return ((java.util.HashMap.TreeNode<K,V>)first).getTreeNode(hash, key);

                // 如果不是红黑树，那么我们就遍历链表。
                do {
                    if (e.hash == hash &&
                            ((k = e.key) == key || (key != null && key.equals(k))))
                        // 找到目的节点并返回。
                        return e;
                } while ((e = e.next) != null);
            }
        }

        // 否则就是没找到。
        return null;
    }
```

### 2.2 方法说明

- **get** 方法它只返回传入 **key** 的对应 **value** ，不会对结构进行修改。
- 它分为如下几个阶段来查找
  - 哈希表是否为空？
  - 哈希表不为空的话，哈希表中对应索引处的桶中有多少个节点？
    - 一个节点。
    - 多个节点。
      - 是否是红黑树？
      - 是否是链表？



## 3、tableSizeFor方法

### 3.1 源码

```java
	/**
     * Returns a power of two size for the given target capacity.
     * 是为了得到一个大于获等于他的2的幂并返回，如给定10，返回 2^4 = 16。
     * 挺有意思的。
     */
    static final int tableSizeFor(int cap) {
        /*
            假设传进来一个数的二进制是100001001；
            >>> 无符号右移。
            |= 从最高位开始。

            n |= n >>> 1;
            第一步过程：
                  100001001
                  010000100
                           或
              -----------------
                  110001101
            在这里处理之后是110001101，这一步可以这样理解，就是n变成n与n右移一位之后异或后的值。
            这也就解释了为什么下一行要无符号右移2，依此类推1，2，4，8，16，下下次直接右移4.
            n |= n >>> 2;
            在这里处理之后是111101111
            n |= n >>> 4;
            在这里处理之后是111111111
            n |= n >>> 8;
            n |= n >>> 16;
         */
        // 这一步是为了防止传入的cap本来就是2的幂，结果处理成 2n+1 了。
        int n = cap - 1; // 就像如果cap是 1000 的话，经过下列处理就会变成 2n+1 了。就得-1 = 0111；
        //相当于 n = n | n >>> 1。
        n |= n >>> 1;
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        n |= n >>> 16;

        // 处理完之后，必然是全1，也就是2幂-1，那么返回n+1。
        // 这样就可以找到是 2 的多少次幂与当前容量最接近了。
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
    }
```

### 3.1  思考

- 使用位运算极大减少了性能消耗，加快了运行速度。
- 详细思考都在上方代码注释中。

## 4、putMapEntries方法

### 4.1 源码

```java
	 /**
     * Implements Map.putAll and Map constructor.
     * 把传入的map里边的元素都加载到当前 hashmap，是上面那个构造函数的具体实现。
     * @param m the map
     * @param evict false when initially constructing this map, else
     * true (relayed to method afterNodeInsertion).
     */
    final void putMapEntries(Map<? extends K, ? extends V> m, boolean evict) {
        // 得到当前传入 map 的键值对个数。
        int s = m.size();

        // 如果键值对个数大于0的话。
        if (s > 0) {

            // 如果当前 hashmap 的哈希表的容量等于空的话。
            // 判断table是否已经初始化。
            if (table == null) { // pre-size

                // HashMap 的容量在 size > capacity * loadFactor 时会扩容。
                // 初始化容量获得，但这里为啥要 +1.0F 不知道欸。
                float ft = ((float)s / loadFactor) + 1.0F;

                // 当前容量是否大于最大值，不是的话容量就是他，否则的话容量就是最大值。
                int t = ((ft < (float)MAXIMUM_CAPACITY) ?
                        (int)ft : MAXIMUM_CAPACITY);

                // 如果设置的容量大于了哈希表的扩容阈值。
                if (t > threshold)
                    // 那么我们的扩容阈值就改为这个东西。
                    threshold = tableSizeFor(t);
            }
            // 否则如果容量大于扩容阈值。
            // 已初始化，并且 m元素 个数大于阈值，进行扩容处理。
            else if (s > threshold)
                // 扩容！
                resize();
            // 将m中的所有元素添加至HashMap中。
            for (Map.Entry<? extends K, ? extends V> e : m.entrySet()) {
                K key = e.getKey();
                V value = e.getValue();
                putVal(hash(key), key, value, false, evict);
            }
        }
    }
```

### 4.2 疑问

- ==初始化容量获得，但这里为啥要 +1.0F 呢？==



## 5、put方法（重点）

### 5.1 源码

```java
    public V put(K key, V value) {
        // 这里调用扰动函数 hash()
        return putVal(hash(key), key, value, false, true);
    }

    /**
     * HashMap 只提供了 put 用于添加元素，putVal 方法只是给 put 方法调用的一个方法，并没有提供给用户使用。
     *
     * Implements Map.put and related methods.
     * 实现了map接口中put和其它相关方法。
     *
     * 如果定位到的数组位置没有元素 就直接插入。
     * 如果定位到的数组位置有元素就和要插入的 key 比较，
     * 如果 key 相同就直接覆盖，如果 key 不相同，就判断 p 是否是一个树节点，如果是就调用e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value)将元素添加进入。
     * 如果不是就遍历链表插入(插入的是链表尾部)。
     * @param hash hash for key key的hashcode
     * @param key the key 原来的key
     * @param value the value to put key对应的value
     *
     * @param onlyIfAbsent if true, don't change existing value 如果为true，则不更改现有值。
     * @param evict if false, the table is in creation mode. 如果为false，则表处于创建模式。
     *
     * @return previous value, or null if none
     */
    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {

        // tab 引用当前存放数据的哈希表 table。
        java.util.HashMap.Node<K,V>[] tab;
        // p 表示当前哈希表的元素。
        java.util.HashMap.Node<K,V> p;
        // n 为哈希表的长度，i 为 key 的路由寻址结果。
        int n, i;

        // 如果此时当前hashmap的哈希表为空，或者长度为零的话进行扩容。
        // 第一次 put 值的时候，会触发下面的 resize()，类似 java7 的第一次 put 也要初始化数组长度。
        // 进来这一步就说明我们是第一次往当前哈希表里加入值。
        if ((tab = table) == null || (n = tab.length) == 0) {
            // 第一次 resize 和后续的扩容有些不一样，因为这次是数组从 null 初始化到默认的 16 或自定义的初始容量。
            n = (tab = resize()).length; // 扩容后的容量赋值给 n。
        }

        // (n - 1) & hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中)
        if ((p = tab[i = (n - 1) & hash]) == null) {
            // 桶都空了说明不可能桶中装的是红黑树了，直接将该节点放入桶中作为第一个元素。
            tab[i] = newNode(hash, key, value, null);
        } else {

            // 如果此时桶中存在元素。
            java.util.HashMap.Node<K,V> e; // 临时节点。
            K k; // 临时key。

            // 首先，判断该位置的第一个数据和我们要插入的数据，key 是不是"相等"。
            if (p.hash == hash &&
                    ((k = p.key) == key || (key != null && key.equals(k)))) {

                // 如果是，取出这个节点。
                e = p;

            } else if (p instanceof java.util.HashMap.TreeNode) {

                // 如果该节点是代表红黑树的节点，调用红黑树的增加节点的方法。
                e = ((java.util.HashMap.TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            } else {

                /*
                    插入到链表的最后面(Java7 是插入到链表的最前面)。
                 */
                // 到这一步说明当哈希表这个桶中的是一条链表，执行尾插法插入当前桶的 entry 链表尾部。
                for (int binCount = 0; ; ++binCount) {

                    // 遍历到达链表的尾部。
                    if ((e = p.next) == null) {

                        // 在尾部插入新结点。
                        p.next = newNode(hash, key, value, null);

                        // 这个方法会根据 HashMap 数组来决定是否转换为红黑树。
                        // 只有当数组长度大于或者等于 64 的情况下，才会执行转换红黑树操作，以减少搜索时间。否则，就是只是对数组扩容。
                        // 如果插入后结点的数量到链表转红黑树的阈值，就执行 treeifyBin 方法。
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            // TREEIFY_THRESHOLD 为 8，所以，如果新插入的值是链表中的第 8 个。
                            // 会触发下面的 treeifyBin，也就是将当前桶中链表转换为红黑树。
                            treeifyBin(tab, hash);
                        break;
                    }

                    // 如果在该链表中找到了与待插入节点相等的 key(== 或 equals)。
                    if (e.hash == hash &&
                            ((k = e.key) == key || (key != null && key.equals(k)))) {
                        // 此时 break，那么 e 此时就是链表中[与要插入的新值的 key "相等"]的 node
                        break;
                    }

                    // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表。
                    p = e;
                }
            }

            // 循环遍历结束如果 e 不为 null 的话说明存在旧值的 key 与要插入的 key 相等的情况。
            // 对于put操作，下面这个 if 就是进行 "值覆盖"，然后返回旧值，不更改结构。
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }

        ++modCount;

        // 如果哈希表由于新插入这个值导致 size 已经超过了阈值，需要进行扩容。
        /*
            Java7 稍微有点不一样的地方就是，Java7 是先扩容后插入新值的，Java8 先插值再扩容。
         */
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }
```

### 5.5 执行流程

![image-20211105210142612](C:\Users\noblegasesgoo\AppData\Roaming\Typora\typora-user-images\image-20211105210142612.png)



## 6、resize方法（重点扩容）

### 6.1 源码

```java
 	/**
     * Initializes or doubles table size.  If null, allocates in
     * accord with initial capacity target held in field threshold.
     * Otherwise, because we are using power-of-two expansion, the
     * elements from each bin must either stay at same index, or move
     * with a power of two offset in the new table.
     * 初始化或加倍表大小。如果为空，则按照字段阈值中持有的初始容量目标进行分配。
     * 否则，由于使用的是2的幂展开，每个容器中的元素必须保持相同的索引，或者在新表中以2的幂移动。
     * 哈希表扩容的方法。
     * @return the table
     */
    final java.util.HashMap.Node<K,V>[] resize() {

        // 保存修改容量前的哈希表。
        java.util.HashMap.Node<K,V>[] oldTab = table;

        // 记录老哈希表容量，如果老哈希表没有键值对也就是没有内容的时候，就为0，否则就为老哈希表的长度。
        int oldCap = (oldTab == null) ? 0 : oldTab.length;
        // 记录老哈希表扩容阈值。
        // threshold = capacity * loadFactor
        int oldThr = threshold;
        // 新建要返回的扩容后的哈希表的容量和扩容阈值。
        int newCap, newThr = 0;

        /*
             这一步对应哈希表扩容。
         */
        // 如果老容量大于0了。
        if (oldCap > 0) {
            // 如果老容量不仅大于0还大于等于哈希表最大容量了。
            if (oldCap >= MAXIMUM_CAPACITY) {
                // 直接给你扩容阈值设置为 int 的最大值。
                // 直接一步到位，给你扩都没地方扩。
                threshold = Integer.MAX_VALUE;
                // 返回扩容后的哈希表。
                return oldTab;
            }
            // 将新容量赋值为老容量的两倍之后，如果还小于系统最大哈希表容量并且！老容量在大于我们hashmap默认容量 2^4 的话。
            // 直接进行将新容量放大为老容量的两倍，例如容量 2^4 ---> 2^5。
            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                    oldCap >= DEFAULT_INITIAL_CAPACITY)
                // 再将阈值扩大一倍。
                newThr = oldThr << 1; // double threshold。

        /*
             这一步对使用 new HashMap(int initialCapacity) 初始化后，第一次 put 的时候。
         */
        } else if (oldThr > 0) // initial capacity was placed in threshold 初始容量设置为threshold。
            // 如果到这里了，是因为我们初始化哈希表没有传入值，我们直接进行一个老容量赋值为默认容量大小。
            // 老哈希表的新容量就为扩容阈值，也就是默认的 2^4。
            newCap = oldThr;
        else {
            /*
                对应使用 new HashMap() 初始化后，第一次 put 的时候。
             */
            // zero initial threshold signifies using defaults 零初始阈值表示使用默认值。
            // 否则如果到了这一步就是，哈希表第一次创建，使用默认值生成相关参数。
            newCap = DEFAULT_INITIAL_CAPACITY; // 默认为 2^4。
            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); // 默认负载因子设置。
        }

        // 计算新的 扩容阈值 上限。
        if (newThr == 0) {
            // 得到当前扩容阈值。
            float ft = (float)newCap * loadFactor;
            // 新的扩容阈值赋值
            // 如果当前容量小于最大容量 并且 当前扩容的阈值小于最大容量。
            // 新的扩容阈值就为：ft
            // 否则就为：int的最大值。
            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                    (int)ft : Integer.MAX_VALUE);
        }

        /*
            到 table = newTab; 这句代码为止，我们新扩容的表的一切属性都设置完毕。
            新属性包括新容量，新的扩容阈值。
         */
        // 将当前哈希表的扩容阈值就为我们最新计算出来的。
        threshold = newThr;

        // 作用是屏蔽一些无关紧要的警告。使开发者能看到一些他们真正关心的警告。
        @SuppressWarnings({"rawtypes","unchecked"})
        // 新建一个哈希表，它的容量就为我们的初始扩容阈值。
        // 用新的数组大小初始化新的数组。
        java.util.HashMap.Node<K,V>[] newTab = (java.util.HashMap.Node<K,V>[])new java.util.HashMap.Node[newCap];

        // 将旧表替换为阔玩容的新表。
        // 新表的扩容阈值已经在上面几步计算完毕。
        table = newTab;


        // 如果旧表不是空的话。
        if (oldTab != null) {
            // 开始遍历原哈希表，进行数据迁移。
            for (int j = 0; j < oldCap; ++j) {
                // 临时节点，用来链表迁移。
                java.util.HashMap.Node<K,V> e;
                // 如果老表中的第j个桶中有数据的话。并将桶中第一个节点保存。
                if ((e = oldTab[j]) != null) {
                    // 将老表中的第j个桶设为空，并保存该桶的节点。
                    oldTab[j] = null;
                    // 如果这个桶中取出来的第一个节点没有下一个节点，简单迁移这个元素就可以了。
                    if (e.next == null)
                        // 重新计算这个节点对应新桶的位置，并进行节点迁移。
                        newTab[e.hash & (newCap - 1)] = e;
                    // 如果此时这个 e 节点是一个红黑树节点的话。
                    else if (e instanceof java.util.HashMap.TreeNode)
                        // 这步的意思是不是将该节点转换为树种节点。
                        ((java.util.HashMap.TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                    else { // preserve order

                        // 这块是处理链表的情况。
                        // 需要将此链表拆成两个链表，放到新的数组中，并且保留原来的先后顺序。
                        java.util.HashMap.Node<K,V> loHead = null, loTail = null; // loHead、loTail 对应一条链表。对应扩容前位置的链表。
                        java.util.HashMap.Node<K,V> hiHead = null, hiTail = null; // hiHead、hiTail 对应另一条链表。对应扩容后位置的链表。
                        java.util.HashMap.Node<K,V> next; // 下一个节点。

                        do {
                            // next 指向 e节点 的下一个节点。
                            next = e.next;
                            // 判断当前节点的 hashcode 值的比哈希表容量高一位的二进制位是否为1，如果为0，则节点保持原桶，如果为1，到新桶。
                            // 等于0时，则将该头节点放到新哈希表时的索引位置等于其在旧哈希表的索引位置,记为低位区链表lo开头-low。
                            if ((e.hash & oldCap) == 0) {
                                if (loTail == null) // 低位链表尾部如果为空。
                                    loHead = e; // 当前节点就设置为链表头。
                                else
                                    // 否则当前节点追加到尾节点的下一节点。
                                    loTail.next = e;
                                // 将此时尾节点设置为当前节点。
                                loTail = e;
                            } else {
                                // 不等于0时,则将该头节点放到新哈希表时的索引位置等于其在旧哈希表时的索引位置再加上旧哈希表长度，记为高位区链表hi开头high。
                                if (hiTail == null)
                                    hiHead = e;
                                else
                                    hiTail.next = e;
                                hiTail = e;
                            }
                        } while ((e = next) != null);

                        // 这里就是将那些不用移动到新索引的节点存储到旧表在新表中的映射位置。
                        if (loTail != null) {
                            loTail.next = null;
                            newTab[j] = loHead;
                        }
                        // 这里就是将那些要移动到新索引的节点存储到新表中的位置。
                        if (hiTail != null) {
                            hiTail.next = null;
                            newTab[j + oldCap] = hiHead;
                        }
                    }
                }
            }
        }

        // 返回新表！终于看完了。
        return newTab;
    }
```

### 6.1 思考

- 扩容为什么要尽可能的去避免？
  - 因为每次进行扩容，会伴随着一次重新 hash 分配，并且会遍历 hash 表中所有的元素，这样挺浪费时间的。
- 怎么去尽可能的避免呢？
  - 目前我只能想到设置一个合适的初始值来避免。



## 7、JDK1.8中哈希冲突解决的方法

### 7.1 抖动函数

```java
static final int hash(Object key) {
        int h;

        /*
            摘自：https://link.csdn.net/?target=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F20733617：
                在java1.7中：
                    理论上散列值是一个int型，如果直接拿散列值作为下标访问HashMap主数组的话，考虑到2进制32位带符号
                    的int表值范围从-2147483648到2147483648。
                    前后加起来大概40亿的映射空间。只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。
                    但问题是一个40亿长度的数组，内存是放不下的。你想，HashMap扩容之前的数组初始大小才16。所以这个
                    散列值是不能直接拿来用的。用之前还要先做对数组的长度取模运算，得到的余数才能用来访问数组下标。
                    源码中模运算是在这个indexFor()函数里完成的。

                    static int indexFor(int h, int length) {
                        return h & (length-1);
                    } 就是把 key 的 hash值对数组长度做与运算。

                    但这时候问题就来了，这样就算我的散列值分布再松散，要是只取最后几位的话，碰撞也会很严重。更要命的
                    是如果散列本身做得不好，分布上成等差数列的漏洞，恰好使最后几个低位呈现规律性重复，就无比蛋疼。
                    所以我们的扰动函数就登场了，
         */
        /*
            通过以上的内容，顺便理解一下hashmap为什么数组容量是 2的幂，比如 数组默认初始长度为 2^4 = 16，二进制就是 0001 0000，
            而这边 length-1之后，就是 0000 1111，此时假设我们传入的 kye 的 hash 值为，0011 0110。

            0011 0110
            0000 1111
                    &
            ---------
            0000 0110 = 6 此时 hash 值为6的这个 key 就存在哈希表下标为6处。
            这样不管什么样的hash值，范围与运算之后都在 0 ~ 15 内。所以这就是为啥哈希表初始长度得是 2的幂 的原因。
         */

        // 如果key不为空，就返回 key的hashcode 与上 key的hashcode 右移16位。
        /*
             0001 0110 0111 0011
             0000 0000 0001 0110
                               ^
             -------------------
             0001 0110 0110 0101
         */
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
```



#### 7.1.1 抖动函数思考

- 他是怎么减少哈希冲突的？
  - **key的哈希值**右位移16位，正好是32bit的一半，自己的高半区和低半区做异或，就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来。
  
  

### 7.2 别的解决方法

- java中是选用链地址法。
- jdk1.8引入了红黑树来优化链地址法中链表过长导致的查找慢的问题。
- 还有就是有一个负载因子，来辅助确定哈希表啥时候扩容，扩容的话节点存储就会更散一点，散了冲突就少了，但是会涉及到扩容，消耗性能。



## 8、remove方法

### 8.1 源码

```java

    public V remove(Object key) {
        java.util.HashMap.Node<K,V> e;
        return (e = removeNode(hash(key), key, null, false, true)) == null ?
                null : e.value;
    }

    final java.util.HashMap.Node<K,V> removeNode(int hash, Object key, Object value,
                                                 boolean matchValue, boolean movable) {
        java.util.HashMap.Node<K,V>[] tab; java.util.HashMap.Node<K,V> p; int n, index;

        // 当哈希表不为空，并且 hash值 对应的桶不为空时。
        // 记录当前哈希表，记录当前 key 对应的索引，记录当前 key 所对应的桶的位置中的第一个节点。
        if ((tab = table) != null && (n = tab.length) > 0 &&
                (p = tab[index = (n - 1) & hash]) != null) {
            // 用来记录要删除的头节点。
            java.util.HashMap.Node<K,V> node = null, e; K k; V v;

            // 如果此时桶中只有一个节点，那么就是我们要删除的节点。
            if (p.hash == hash &&
                    ((k = p.key) == key || (key != null && key.equals(k))))
                // 先记录下来。
                node = p;
            // 否则如果要删除的节点是红黑树节点的话。
            else if ((e = p.next) != null) {
                if (p instanceof java.util.HashMap.TreeNode)
                    // 进入树查找要删除的节点。
                    node = ((java.util.HashMap.TreeNode<K,V>)p).getTreeNode(hash, key);
                else {
                    // 否则链表长度不是一的话，循环遍历到要删除的节点。
                    do {
                        // hash值 相等，并且 key 地址相等或者 equals。
                        if (e.hash == hash &&
                                ((k = e.key) == key ||
                                        (key != null && key.equals(k)))) {

                            // 记录要删除的节点。
                            node = e;
                            break;
                        }

                        // 保存一下当前链表中遍历到的节点，下边删除节点的时候会用得到。
                        p = e;
                    } while ((e = e.next) != null);
                }
            }

            // 如果我们要删除的节点不为空的话。
            if (node != null && (!matchValue || (v = node.value) == value ||
                    (value != null && value.equals(v)))) {

                // 如果它不为空且是红黑树节点的话。
                if (node instanceof java.util.HashMap.TreeNode)

                    //在树中删除节点。
                    ((java.util.HashMap.TreeNode<K,V>)node).removeTreeNode(this, tab, movable);
                else if (node == p)
                    // 如果我们要删除的节点是头节点的话。
                    // 当前桶置空。
                    tab[index] = node.next;
                else

                    // 如果我们删除的节点不为空且不是链表头节点将。
                    // 就将当前节点指向删除节点的下一个节点。
                    p.next = node.next;

                // 修改结构 ++modCount
                ++modCount;
                // 键值对个数减少。
                --size;
                afterNodeRemoval(node);
                // 返回被删除的节点。
                return node;
            }
        }
        // 否则删除失败。
        return null;
    }
```

### 8.2 思考

- 如果删除的是红黑树的节点的话，那么重新建树的过程会挺费时间的。
- 所以我们尽量不在有很多数据的 **hashmap** 中随意删除节点。



